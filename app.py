import streamlit as st
import pandas as pd
import docx2txt
import pdfplumber
import re

# --- Cáº¤U HÃŒNH TRANG ---
st.set_page_config(page_title="Trá»£ lÃ½ GiÃ¡o Ãn NLS (Standard)", page_icon="ğŸ“˜")

# --- 1. Tá»ª ÄIá»‚N Dá»® LIá»†U ---
SUBJECT_MAPPING = {
    "ToÃ¡n há»c": {"keywords": ["geogebra", "mÃ¡y tÃ­nh cáº§m tay", "excel", "báº£ng tÃ­nh", "Ä‘á»“ thá»‹", "mÃ´ phá»ng"], "default_id": "5.1TC1a", "action": "tÃ­nh toÃ¡n vÃ  mÃ´ phá»ng"},
    "Ngá»¯ vÄƒn": {"keywords": ["soáº¡n tháº£o", "word", "powerpoint", "slide", "video", "clip", "tra cá»©u", "sÃ¢n kháº¥u hÃ³a"], "default_id": "3.1TC1a", "action": "trÃ¬nh bÃ y vÃ  minh há»a ná»™i dung"},
    "Tiáº¿ng Anh": {"keywords": ["tá»« Ä‘iá»ƒn", "app", "file nghe", "audio", "video", "ghi Ã¢m", "lá»“ng tiáº¿ng", "chat"], "default_id": "2.1TC1a", "action": "luyá»‡n táº­p giao tiáº¿p vÃ  tra cá»©u"},
    "KHTN (LÃ½/HÃ³a/Sinh)": {"keywords": ["thÃ­ nghiá»‡m áº£o", "phet", "mÃ´ phá»ng", "sá»‘ liá»‡u", "kÃ­nh hiá»ƒn vi"], "default_id": "1.2TC1a", "action": "quan sÃ¡t thÃ­ nghiá»‡m vÃ  xá»­ lÃ½ sá»‘ liá»‡u"},
    "Lá»‹ch sá»­ & Äá»‹a lÃ½": {"keywords": ["báº£n Ä‘á»“ sá»‘", "google earth", "lÆ°á»£c Ä‘á»“", "tranh áº£nh", "gps", "tÆ° liá»‡u", "internet"], "default_id": "1.1TC1a", "action": "tra cá»©u tÆ° liá»‡u vÃ  báº£n Ä‘á»“ trá»±c quan"},
    "Tin há»c": {"keywords": ["láº­p trÃ¬nh", "code", "thuáº­t toÃ¡n", "mÃ¡y tÃ­nh", "pháº§n má»m", "internet", "thÆ° má»¥c"], "default_id": "5.4TC1a", "action": "thá»±c hÃ nh thao tÃ¡c mÃ¡y tÃ­nh"},
    "CÃ´ng nghá»‡": {"keywords": ["báº£n váº½", "thiáº¿t káº¿", "cad", "mÃ´ hÃ¬nh", "video hÆ°á»›ng dáº«n", "quy trÃ¬nh"], "default_id": "3.1TC1b", "action": "thiáº¿t káº¿ vÃ  mÃ´ phá»ng ká»¹ thuáº­t"},
    "HÄ Tráº£i nghiá»‡m": {"keywords": ["kháº£o sÃ¡t", "google form", "canva", "poster", "video", "áº£nh", "thuyáº¿t trÃ¬nh"], "default_id": "2.2TC1a", "action": "há»£p tÃ¡c vÃ  chia sáº» káº¿t quáº£"},
    "Nghá»‡ thuáº­t": {"keywords": ["váº½ mÃ¡y", "chá»‰nh áº£nh", "video", "ghi Ã¢m", "nháº¡c cá»¥ áº£o"], "default_id": "3.1TC1a", "action": "sÃ¡ng táº¡o tÃ¡c pháº©m nghá»‡ thuáº­t"},
    "GDTC": {"keywords": ["video", "Ä‘á»“ng há»“ báº¥m giá»", "nhá»‹p tim", "app sá»©c khá»e", "ghi hÃ¬nh"], "default_id": "4.3TC1a", "action": "theo dÃµi chá»‰ sá»‘ vÃ  ká»¹ thuáº­t Ä‘á»™ng tÃ¡c"}
}

# --- 2. LOAD DATA ---
@st.cache_data
def load_nls_data():
    data = {
        'Id': ['1.1TC1a', '1.1TC2b', '1.3TC1a', '2.1TC1a', '2.2TC1a', '3.1TC1a', '3.1TC1b', '4.3TC1a', '5.1TC1a', '5.4TC1a'],
        'Muc': ['TC1', 'TC2', 'TC1', 'TC1', 'TC1', 'TC1', 'TC1', 'TC1', 'TC1', 'TC1'],
        'YCCD': [
            'TÃ¬m kiáº¿m dá»¯ liá»‡u trÃªn mÃ´i trÆ°á»ng sá»‘.',
            'ÄÃ¡nh giÃ¡ nguá»“n tin vÃ  tÃ¬m kiáº¿m nÃ¢ng cao.',
            'LÆ°u trá»¯ vÃ  quáº£n lÃ½ dá»¯ liá»‡u khoa há»c.',
            'TÆ°Æ¡ng tÃ¡c vÃ  giao tiáº¿p qua cÃ´ng nghá»‡.',
            'Chia sáº» thÃ´ng tin vÃ  há»£p tÃ¡c nhÃ³m.',
            'Táº¡o vÃ  chá»‰nh sá»­a ná»™i dung sá»‘ (vÄƒn báº£n, áº£nh, video).',
            'Táº¡o sáº£n pháº©m sá»‘ Ä‘Æ¡n giáº£n thá»ƒ hiá»‡n báº£n thÃ¢n.',
            'Báº£o vá»‡ sá»©c khá»e vÃ  an toÃ n khi dÃ¹ng cÃ´ng nghá»‡.',
            'Giáº£i quyáº¿t lá»—i ká»¹ thuáº­t Ä‘Æ¡n giáº£n.',
            'Tá»± há»c vÃ  cáº­p nháº­t kiáº¿n thá»©c sá»‘.'
        ]
    }
    df = pd.DataFrame(data)
    df_tc2 = df.copy()
    df_tc2['Muc'] = 'TC2'
    return pd.concat([df, df_tc2])

def read_file(uploaded_file):
    try:
        if uploaded_file.name.endswith('.docx'): return docx2txt.process(uploaded_file)
        elif uploaded_file.name.endswith('.pdf'):
            text = ""
            with pdfplumber.open(uploaded_file) as pdf:
                for page in pdf.pages: text += page.extract_text() + "\n"
            return text
    except: return ""

# --- 3. LOGIC PHÃ‚N TÃCH (KHÃ”NG AI) ---
def analyze_final(text, df, subject):
    text_lower = text.lower()
    subj_info = SUBJECT_MAPPING.get(subject, {"keywords": [], "default_id": "", "action": "sá»­ dá»¥ng cÃ´ng nghá»‡"})
    
    # TÃ¬m cÃ´ng cá»¥
    found_tools = [kw for kw in subj_info["keywords"] if kw in text_lower]
    if not found_tools: found_tools = ["thiáº¿t bá»‹ sá»‘", "internet", "pháº§n má»m", "tÃ i liá»‡u sá»‘"]

    # TÃ¬m ID
    matched_ids = []
    for _, row in df.iterrows():
        yccd_words = [w for w in row['YCCD'].lower().split() if len(w) > 4]
        match = sum(1 for w in yccd_words if w in text_lower)
        if (match / len(yccd_words) if yccd_words else 0) > 0.4: matched_ids.append(row)
    
    if not matched_ids and subj_info["default_id"]:
        defs = df[df['Id'] == subj_info["default_id"]]
        if not defs.empty: matched_ids.append(defs.iloc[0])

    # Káº¿t quáº£
    results = []
    seen = set()
    for row in matched_ids[:2]:
        if row['Id'] in seen: continue
        seen.add(row['Id'])

        # Táº O CÃ‚U GIáº¢I THÃCH Tá»° Äá»˜NG (Template Logic)
        tools_display = ", ".join(found_tools[:2])
        explanation = (
            f"ğŸ“ **Gá»£i Ã½ hoáº¡t Ä‘á»™ng:**\n"
            f"Há»c sinh sá»­ dá»¥ng **{tools_display}** Ä‘á»ƒ thá»±c hiá»‡n viá»‡c {subj_info['action']}.\n"
            f"âœ… **Sáº£n pháº©m Ä‘áº§u ra:** BÃ i trÃ¬nh chiáº¿u, Video bÃ¡o cÃ¡o, hoáº·c Phiáº¿u há»c táº­p sá»‘ hÃ³a.\n"
            f"ğŸ‘‰ Hoáº¡t Ä‘á»™ng nÃ y Ä‘Ã¡p á»©ng yÃªu cáº§u cáº§n Ä‘áº¡t: '{row['YCCD']}'."
        )

        results.append({
            "id": row['Id'],
            "yccd": row['YCCD'],
            "exp": explanation
        })
    return results

# --- 4. GIAO DIá»†N ---
st.title("ğŸ“˜ Trá»£ lÃ½ GiÃ¡o Ãn NLS (Báº£n Chuáº©n)")
st.caption("PhÃ¢n tÃ­ch nhanh - ChÃ­nh xÃ¡c - á»”n Ä‘á»‹nh")
st.markdown("---")

col1, col2 = st.columns(2)
grade = col1.selectbox("Khá»‘i lá»›p", ["Lá»›p 6", "Lá»›p 7", "Lá»›p 8", "Lá»›p 9"])
subject = col2.selectbox("MÃ´n há»c", list(SUBJECT_MAPPING.keys()))
uploaded_file = st.file_uploader("Táº£i giÃ¡o Ã¡n (Word/PDF)", type=['docx', 'pdf'])

if uploaded_file and st.button("PHÃ‚N TÃCH"):
    target = 'TC1' if grade in ['Lá»›p 6', 'Lá»›p 7'] else 'TC2'
    with st.spinner("Äang phÃ¢n tÃ­ch dá»¯ liá»‡u..."):
        content = read_file(uploaded_file)
        if len(content) < 50: st.warning("KhÃ´ng tÃ¬m tháº¥y NÄƒng lá»±c sá»‘")
        else:
            df = load_nls_data()
            res = analyze_final(content, df[df['Muc'] == target], subject)
            
            st.divider()
            if res:
                st.success(f"âœ… TÃ¬m tháº¥y {len(res)} Ä‘á» xuáº¥t!")
                # ThÃªm enumerate Ä‘á»ƒ trÃ¡nh lá»—i hiá»ƒn thá»‹ key
                for i, item in enumerate(res):
                    with st.expander(f"ğŸ“Œ MÃ£: {item['id']}", expanded=True):
                        st.markdown("**1. YÃªu cáº§u cáº§n Ä‘áº¡t:**")
                        st.code(f"{item['id']}: {item['yccd']}", language="text")
                        st.markdown("**2. Giáº£i thÃ­ch & Sáº£n pháº©m:**")
                        st.info(item['exp'])
            else:
                st.warning("KhÃ´ng tÃ¬m tháº¥y NÄƒng lá»±c sá»‘ cho bÃ i há»c nÃ y")